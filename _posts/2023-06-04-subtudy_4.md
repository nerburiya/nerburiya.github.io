---
title:  "[숩터디] 2주차 1"
excerpt: "Joonseok Lee 교수님의 Lecture 4. Convolutional Neural Networks 강의 요약"

categories:
  - Blog
tags:
  - [Blog, Deeplearning, Github, SNU]

toc: true
toc_sticky: true
 
date: 2020-06-04
last_modified_at: 2023-06-04
---

# Fully-connected Layer 
- 모든 입력과 출력이 노드로 연결됨.

# CNN
- 기존에는 필터를 만들어서 적용해서 유사성을 픽셀단위로 계산했었음.
- def conv(image, filter, threshold): 꼭 한번 작성해보면 좋음. 생각보다 어렵고 잘 못함(엔비디아에서 면접에서 물어봄)
- 필터를 어떻게 찾고 디자인할 것인가? 
- 딥러닝은 data로부터 패턴과 필터를 찾는다
- spatial locality : 근처의 픽셀만 보면 특정 자료를 찾을 수 있음.
- positional invariance : 같은 필터는 그 이미지에 있는 모든 자리에 적용이 가능함.
- 위의 두 가정은 엑스레이 이미지처럼 위치가 정해진 경우에는 맞지 않을 수 있음.

## convolutional layer
- convolution : 필터가 순회하면서 dot product를 실시후 모두 합침
- 필터는 채널 수만큼 쌓아서 만든다.
- stride : 필터가 이동하는 거리
- padding : 주변에 0인 값을 채워넣는 것
- (이미지의 크기 – 필터의 크기+2 * 패딩) / stride +1이 출력의 사이즈
- 패딩의 크기를 (필터의 크기 –1)/2로 하면 크기가 보존됨. (stride =1)
- 파라미터의 크기는 (필터의 크기 * 채널의 크기+1(바이어스)) * (필터의 개수)
- fully-connected인 경우 (아웃풋의 크기) * (인풋의 크기 +1(바이어스))이므로 훨씬 적은 파라미터로 표현이 가능함. spatial locality, positional invariance 이 두 가정으로 가능한 것임.
- 1 * 1 필터는 차원을 바꿀 때 사용(다른 값들을 섞지 않고 차원만 바꿀 수 있음)

## torch.nn.Conv2d : 파라미터 정리(예정) [57분]

## nested conv-layers
- 이미지 – 낮은 수준의 특징 – 중간 수준의 특징 – 높은 수준의 특징 – 분류모델 – 분류
- 이런 목표를 위해 층을 여러개 쌓는 것
- fully-connected와 convolution은 서로의 특별한 경우임

## pooling layer
- 크기를 줄이기 위한 층, denoising 효과가 있다.
- 가장 큰 값을 가져오는 max-pooling, 평균을 가져오는 average-pooling
- (입력 – 필터의 크기) / stride +1로 크기가 변경된다.
- 채널은 그대로 들어온다. (채널별로 연산함)
- 평균을 내거나 최대인 값을 가져오기 때문에 학습할 파라미터가 없음
